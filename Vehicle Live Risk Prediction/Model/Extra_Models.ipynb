{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bc812ed-e9f4-4794-82b3-eabb0ff7571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"/home/keshav/Downloads/Vehicle Risk Prediction Dataset.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "le_visibility = LabelEncoder()\n",
    "le_road_surface_conditions = LabelEncoder()\n",
    "le_weather = LabelEncoder()\n",
    "le_traffic_density = LabelEncoder()\n",
    "le_road_hazards = LabelEncoder()\n",
    "#le_time_of_day = LabelEncoder()\n",
    "le_fatigue_level = LabelEncoder()\n",
    "le_medical_condition = LabelEncoder()\n",
    "le_speeding = LabelEncoder()\n",
    "le_light= LabelEncoder()\n",
    "#le_road_type=LabelEncoder()\n",
    "#le_landscape=LabelEncoder()\n",
    "\n",
    "df['visibility_n'] = le_visibility.fit_transform(df['Visibility'])\n",
    "df['road_surface_conditions_n'] = le_road_surface_conditions.fit_transform(df['Road_Surface_Conditions'])\n",
    "df['weather_n'] = le_weather.fit_transform(df['Weather'])\n",
    "df['traffic_density_n'] = le_traffic_density.fit_transform(df['Traffic_Density'])\n",
    "df['road_hazards_n'] = le_road_hazards.fit_transform(df['Road_Hazards'])\n",
    "#df['time_of_day_n'] = le_time_of_day.fit_transform(df['Time_of_Day'])\n",
    "df['fatigue_level_n'] = le_fatigue_level.fit_transform(df['Fatigue_Level'])\n",
    "df['medical_condition_n'] = le_medical_condition.fit_transform(df['Medical_Condition'])\n",
    "df['speeding_n'] = le_speeding.fit_transform(df['Speeding'])\n",
    "df['light_condition']=le_light.fit_transform(df['Light_Conditions'])\n",
    "#df['roadtype'] = le_road_type.fit_transform(df['Road_Type'])\n",
    "#df['landscape_n']=le_landscape.fit_transform(df['Landscape'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4e4860f-2fd9-491c-90d3-037101f30bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Light_Conditions', 'Road_Type', 'Landscape', 'Visibility', 'Road_Surface_Conditions', 'Weather', 'Traffic_Density', 'Road_Hazards', 'Time_of_Day', 'Fatigue_Level', 'Medical_Condition', 'Speeding','Driver_Age','Last_Service_Months_Ago'], axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d380cf-882d-455c-9ea6-7e05b3c4d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03247239784420999\n",
      "R^2 Score: 0.8634195445701373\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Risk_Score', axis=1)\n",
    "y = df['Risk_Score'].apply(lambda x: 1 if x > 50 else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Lasso regression model\n",
    "model = Lasso(alpha=0.1)  # You can adjust the alpha (regularization strength) parameter\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd19bbbb-e785-43e6-bc11-16a3d0c7b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.007214250517408194\n",
      "R^2 Score: 0.9696565179454888\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1.0)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2bb856-0509-4d36-b004-ac3f657127e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1168\n",
      "           1       1.00      1.00      1.00      1832\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Create and train the Gradient Boosting model\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc0eb215-0d5e-4f39-9d34-6788e03c5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "600/600 [==============================] - 5s 6ms/step - loss: 0.0338 - accuracy: 0.9944 - val_loss: 0.0135 - val_accuracy: 0.9983\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0153 - val_accuracy: 0.9983\n",
      "Epoch 3/3\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.2283e-04 - accuracy: 0.9998 - val_loss: 0.0171 - val_accuracy: 0.9983\n",
      "94/94 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.9996666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1168\n",
      "           1       1.00      1.00      1.00      1832\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create an Artificial Neural Network model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=3, batch_size=16, validation_split=0.2)#if i take more epoch it gonna give same output..tested with 10,20 epochs\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a7448-5b3c-411c-9baa-aba650f165f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
